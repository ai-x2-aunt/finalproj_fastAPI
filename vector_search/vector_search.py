import logging
from typing import List, Set
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.docstore.document import Document
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# Set up the embedding model
EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)

# Function to load the existing vector store
def load_vectorstore(persist_dir: str = "./chroma_data") -> Chroma:
    logger.info("Loading existing vector store")
    return Chroma(
        embedding_function=embedding_model,
        collection_name="job_postings",
        persist_directory=persist_dir,
    )

# Function to perform vector search with filtering and duplicate removal
def search_documents(vectorstore: Chroma, query: str, top_k: int = 5) -> List[Document]:
    try:
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬
        query_terms = query.lower().replace(',', ' ').split()
        
        # ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        results = vectorstore.similarity_search(query, k=50)
        
        filtered_results = []
        seen_ids = set()
        
        for doc in results:
            metadata = doc.metadata
            job_id = metadata.get('ì±„ìš©ê³µê³ ID')
            
            # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸ ì¤€ë¹„
            search_text = ' '.join([
                str(metadata.get('ì±„ìš©ì œëª©', '')),
                str(metadata.get('ìƒì„¸ì •ë³´', '')),
                str(metadata.get('íšŒì‚¬ëª…', '')),
                str(metadata.get('ê·¼ë¬´ì§€ì—­', '')),
                str(metadata.get('ì„¸ë¶€ìš”ê±´', '')),
                doc.page_content
            ]).lower()
            
            # ëª¨ë“  ê²€ìƒ‰ì–´ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
            matches_all_terms = all(term in search_text for term in query_terms)
            
            if matches_all_terms and job_id not in seen_ids:
                filtered_results.append(doc)
                seen_ids.add(job_id)

        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„
        if not filtered_results:
            for doc in results:
                metadata = doc.metadata
                job_id = metadata.get('ì±„ìš©ê³µê³ ID')
                
                search_text = ' '.join([
                    str(metadata.get('ì±„ìš©ì œëª©', '')),
                    str(metadata.get('ìƒì„¸ì •ë³´', '')),
                    str(metadata.get('íšŒì‚¬ëª…', '')),
                    str(metadata.get('ê·¼ë¬´ì§€ì—­', '')),
                    str(metadata.get('ì„¸ë¶€ìš”ê±´', '')),
                    doc.page_content
                ]).lower()
                
                # ê²€ìƒ‰ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²°ê³¼ì— ì¶”ê°€
                if any(term in search_text for term in query_terms) and job_id not in seen_ids:
                    filtered_results.append(doc)
                    seen_ids.add(job_id)

        return filtered_results[:top_k]

    except Exception as e:
        logger.error(f"Search error: {e}")
        return []

# Function to display search results
def display_results(search_results: List[Document]):
    if not search_results:
        print("\nâš  ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        return

    print("\n==== ğŸ“Œ ê²€ìƒ‰ëœ ì±„ìš©ê³µê³  ====")
    for i, doc in enumerate(search_results):
        metadata = doc.metadata
        print(f"\nğŸ”¹ **ê³µê³  {i+1}**")
        print(f"- **ì œëª©**: {metadata.get('ì±„ìš©ì œëª©', 'ì •ë³´ ì—†ìŒ')}")
        print(f"- **íšŒì‚¬ëª…**: {metadata.get('íšŒì‚¬ëª…', 'ì •ë³´ ì—†ìŒ')}")
        print(f"- **ê·¼ë¬´ì§€**: {metadata.get('ê·¼ë¬´ì§€ì—­', 'ì •ë³´ ì—†ìŒ')}")
        print(f"- **ê¸‰ì—¬ì¡°ê±´**: {metadata.get('ê¸‰ì—¬ì¡°ê±´', 'ì •ë³´ ì—†ìŒ')}")
        print(f"- **ì±„ìš©ê³µê³  URL**: {metadata.get('ì±„ìš©ê³µê³ URL', 'ì •ë³´ ì—†ìŒ')}")
        print(f"- **ìƒì„¸ì •ë³´**:\n{metadata.get('ìƒì„¸ì •ë³´', 'ì •ë³´ ì—†ìŒ')}")
        print(f"\n- **ì„¸ë¶€ìš”ê±´**:\n{metadata.get('ì„¸ë¶€ìš”ê±´', 'ì •ë³´ ì—†ìŒ')}\n")

# Main function to execute the search
def main():
    vectorstore = load_vectorstore()
    query = input("\nğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    results = search_documents(vectorstore, query)
    display_results(results)

if __name__ == "__main__":
    main()
