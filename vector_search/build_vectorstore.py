import json
import re
import logging
from typing import List
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.docstore.document import Document
from dotenv import load_dotenv
from chromadb.config import Settings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 1ï¸âƒ£ ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# 2ï¸âƒ£ ì„ë² ë”© ëª¨ë¸ ì„¤ì •
EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)

# 3ï¸âƒ£ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
def clean_text(text: str) -> str:
    if not isinstance(text, str):
        return ""
    return re.sub(r'<[^>]+>', '', str(text)).replace("\n", " ").strip()

# 4ï¸âƒ£ JSON ë°ì´í„° ë¡œë“œ
def load_data(json_file: str = "jobs.json") -> dict:
    logger.info(f"Loading data from {json_file}")
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        logger.info(f"Loaded {len(data.get('ì±„ìš©ê³µê³ ëª©ë¡', []))} job postings")
        return data
    except Exception as e:
        logger.error(f"Error loading data: {e}")
        return {"ì±„ìš©ê³µê³ ëª©ë¡": []}

# 5ï¸âƒ£ ì±„ìš© ê³µê³ ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
def prepare_documents(data: dict) -> List[Document]:
    logger.info("Preparing documents from data")
    documents = []

    for item in data.get("ì±„ìš©ê³µê³ ëª©ë¡", []):
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        ê³µê³ ë²ˆí˜¸ = item.get("ê³µê³ ë²ˆí˜¸", "no_id")
        ì±„ìš©ì œëª© = clean_text(item.get("ì±„ìš©ì œëª©", ""))
        íšŒì‚¬ëª… = clean_text(item.get("íšŒì‚¬ëª…", ""))
        ê·¼ë¬´ì§€ì—­ = clean_text(item.get("ê·¼ë¬´ì§€ì—­", ""))
        ê¸‰ì—¬ì¡°ê±´ = clean_text(item.get("ê¸‰ì—¬ì¡°ê±´", ""))
        ì±„ìš©ê³µê³ ID = item.get("ì±„ìš©ê³µê³ ID", "ì •ë³´ ì—†ìŒ")
        ì±„ìš©ê³µê³ URL = item.get("ì±„ìš©ê³µê³ URL", "ì •ë³´ ì—†ìŒ")
        
        # ìƒì„¸ì •ë³´ ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        ìƒì„¸ì •ë³´ = item.get("ìƒì„¸ì •ë³´", {})
        ì§ë¬´ë‚´ìš© = ""
        ì„¸ë¶€ìš”ê±´_í…ìŠ¤íŠ¸ = ""
        
        if isinstance(ìƒì„¸ì •ë³´, dict):
            ì§ë¬´ë‚´ìš© = clean_text(ìƒì„¸ì •ë³´.get("ì§ë¬´ë‚´ìš©", ""))
            
            # ì„¸ë¶€ìš”ê±´ ì²˜ë¦¬
            ì„¸ë¶€ìš”ê±´_ë¦¬ìŠ¤íŠ¸ = ìƒì„¸ì •ë³´.get("ì„¸ë¶€ìš”ê±´", [])
            ì¤‘ìš”_í•„ë“œ = {
                "ëª¨ì§‘ì§ì¢…": "ëª¨ì§‘ì§ì¢…",
                "ê²½ë ¥ì¡°ê±´": "ê²½ë ¥ì¡°ê±´",
                "í•™ë ¥": "í•™ë ¥",
                "ê³ ìš©í˜•íƒœ": "ê³ ìš©í˜•íƒœ",
                "ì„ê¸ˆì¡°ê±´": "ì„ê¸ˆì¡°ê±´",
                "ê·¼ë¬´ì˜ˆì •ì§€": "ê·¼ë¬´ì˜ˆì •ì§€",
                "ê·¼ë¬´ì‹œê°„": "ê·¼ë¬´ì‹œê°„",
                "ê·¼ë¬´í˜•íƒœ": "ê·¼ë¬´í˜•íƒœ",
                "ì ‘ìˆ˜ë§ˆê°ì¼": "ì ‘ìˆ˜ë§ˆê°ì¼",
                "ì „í˜•ë°©ë²•": "ì „í˜•ë°©ë²•"
            }
            
            for ìš”ê±´ in ì„¸ë¶€ìš”ê±´_ë¦¬ìŠ¤íŠ¸:
                for key, value in ìš”ê±´.items():
                    if key in ì¤‘ìš”_í•„ë“œ:
                        if isinstance(value, list):
                            ì„¸ë¶€ìš”ê±´_í…ìŠ¤íŠ¸ += f"{ì¤‘ìš”_í•„ë“œ[key]}: {' '.join(value)}\n"
                        else:
                            ì„¸ë¶€ìš”ê±´_í…ìŠ¤íŠ¸ += f"{ì¤‘ìš”_í•„ë“œ[key]}: {value}\n"
        else:
            ì§ë¬´ë‚´ìš© = clean_text(str(ìƒì„¸ì •ë³´))

        # ë°ì´í„° ê²€ì¦
        if not ì§ë¬´ë‚´ìš©:
            logger.warning(f"ì§ë¬´ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {ì±„ìš©ì œëª©}")
            ì§ë¬´ë‚´ìš© = "ìƒì„¸ì •ë³´ ì—†ìŒ"
        
        if not ì±„ìš©ê³µê³ URL:
            logger.warning(f"URLì´ ë¹„ì–´ìˆìŒ: {ì±„ìš©ì œëª©}")

        metadata = {
            "ê³µê³ ë²ˆí˜¸": ê³µê³ ë²ˆí˜¸,
            "ì±„ìš©ì œëª©": ì±„ìš©ì œëª©,
            "íšŒì‚¬ëª…": íšŒì‚¬ëª…,
            "ê·¼ë¬´ì§€ì—­": ê·¼ë¬´ì§€ì—­,
            "ê¸‰ì—¬ì¡°ê±´": ê¸‰ì—¬ì¡°ê±´,
            "ì±„ìš©ê³µê³ ID": ì±„ìš©ê³µê³ ID,
            "ì±„ìš©ê³µê³ URL": ì±„ìš©ê³µê³ URL,
            "ìƒì„¸ì •ë³´": ì§ë¬´ë‚´ìš©,
            "ì„¸ë¶€ìš”ê±´": ì„¸ë¶€ìš”ê±´_í…ìŠ¤íŠ¸
        }

        # ê²€ìƒ‰ìš© í†µí•© í…ìŠ¤íŠ¸
        combined_content = f"{ì±„ìš©ì œëª©} {íšŒì‚¬ëª…} {ê·¼ë¬´ì§€ì—­} {ê¸‰ì—¬ì¡°ê±´} {ì§ë¬´ë‚´ìš©} {ì„¸ë¶€ìš”ê±´_í…ìŠ¤íŠ¸}"
        
        doc = Document(page_content=combined_content, metadata=metadata)
        documents.append(doc)
        
        # ë°ì´í„° ë¡œê¹…
        logger.info(f"\n=== ë¬¸ì„œ ìƒì„± ===")
        logger.info(f"ì œëª©: {ì±„ìš©ì œëª©}")
        logger.info(f"íšŒì‚¬: {íšŒì‚¬ëª…}")
        logger.info(f"URL: {ì±„ìš©ê³µê³ URL}")
        logger.info(f"ìƒì„¸ì •ë³´ ê¸¸ì´: {len(ì§ë¬´ë‚´ìš©)}")
        logger.info(f"ì„¸ë¶€ìš”ê±´ ê¸¸ì´: {len(ì„¸ë¶€ìš”ê±´_í…ìŠ¤íŠ¸)}")
        logger.info("-" * 50)

    logger.info(f"ì´ {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return documents

# 9ï¸âƒ£ ë²¡í„° DB ì €ì¥ í•¨ìˆ˜
def build_vectorstore(documents: List[Document], persist_dir: str = "./chroma_data") -> Chroma:
    logger.info("Building vector store")
    
    try:
        # Chroma ì„¤ì •
        client_settings = Settings(
            anonymized_telemetry=False
        )
        
        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=embedding_model,
            collection_name="job_postings",
            persist_directory=persist_dir,
            client_settings=client_settings
        )
        
        # ì €ì¥ í™•ì¸
        collection = vectorstore._collection
        total_docs = collection.count()
        logger.info(f"Successfully stored {total_docs} documents")
        
        if total_docs == 0:
            logger.error("No documents were stored!")
            
        return vectorstore
        
    except Exception as e:
        logger.error(f"Error building vector store: {e}")
        raise

# ğŸ”Ÿ ì‹¤í–‰ í•¨ìˆ˜
def main():
    try:
        # ë°ì´í„° ë¡œë“œ
        data = load_data()
        if not data.get('ì±„ìš©ê³µê³ ëª©ë¡'):
            logger.error("No job postings found in data!")
            return
            
        # ë¬¸ì„œ ì¤€ë¹„
        docs = prepare_documents(data)
        if not docs:
            logger.error("No documents were prepared!")
            return
            
        # ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = build_vectorstore(docs)
        
        # ì €ì¥ í™•ì¸
        collection = vectorstore._collection
        total_docs = collection.count()
        logger.info(f"\n=== ìµœì¢… í™•ì¸ ===")
        logger.info(f"ì´ ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {total_docs}")
        
    except Exception as e:
        logger.error(f"Error in main: {e}")

if __name__ == "__main__":
    main()
